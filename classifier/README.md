# How to train tensorflow models

The steps provided here are taken from [here](https://github.com/alex-lechner/Traffic-Light-Classification), I'll just add a couple of details.
These steps have been successfully run on Ubuntu 16.04 LTS.

First of all we'll start by installing the dependencies:
- `pip install tensorflow-gpu==1.3` You can install standard tensorflow if you don't have a GPU but it's not recommended as training will be painfully slow. We'll be using version 1.3 since that's the one running on Carla at the moment of writing.
- `sudo apt-get install protobuf-compiler python-pil python-lxml python-tk`
- Go to a folder of your choice to download the tensorflow object detection repo and execute `git clone https://github.com/tensorflow/models.git`
- Navigate to the `models` directory in the Command Prompt and execute `git checkout f7e99c0`. **This checkout is important!**
- Navigate to the `research` folder and execute `protoc object_detection/protos/*.proto --python_out=.`
- Now execute ``export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim`` You'll have to do this on every new Command Prompt you open unless you put it in the `~/.bashrc` file
- If the steps 6 & 7 executed without any errors then execute `python object_detection/builders/model_builder_test.py`

## Training

### Create the workspace structure
Create a folder that will serve as our workspace.
```
mkdir workspace
cd workspace
mkdir models
mkdir data
mdkir frozen_models
```

Now we'll get the [dataset](https://github.com/coldKnight/TrafficLight_Detection-TensorFlowAPI#get-the-dataset) for training.
`cd` to the data folder, download and unzip the contents. Move the contents of the data folder generated by unzipping to the current level (instead of them being in /workspace/data/data, they'll be directly in /workspace/data). Remove the empty data folder (workspace/data/data).

Download the labels [file](https://github.com/alex-lechner/Traffic-Light-Classification/blob/master/data/udacity_label_map.pbtxt) in the current directory.

### Get the model

[SSD Inception V2 Coco (11/06/2017)](http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_11_06_2017.tar.gz) Pro: Very fast, Con: Low precision

[Faster RCNN Inception V2 Coco (28/01/2018)](http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz) Pro: Good precision, Con: Slow

[Faster RCNN Resnet101 Coco (11/06/2017)](http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_11_06_2017.tar.gz) Pro: Highly Accurate, Con: Very slow

`cd` to the models directory and untar the model. `cd` inside the model directory and download the appropriate config [file](https://github.com/alex-lechner/Traffic-Light-Classification/tree/master/config).
We'll rename the config file for ease of use. `mv <name>.config pipeline.config`.
Now we need to change the path references of the config file.

Change the `fine_tune_checkpoint` variable to `fine_tune_checkpoint: "models/faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt"`

The actual file to use for training and validation can be changed, in this example we'll configure it so that it uses real image data to train and simulator data to validate.
Change the `train_input_reader` variable to 
```
train_input_reader: {
  tf_record_input_reader {
    input_path: "data/real_data.record"
  }
  label_map_path: "data/label_map.pbtxt"
}
```

Changing `eval_input_reader` is not necessary unless you want to validate later, but we'll change it anyway
```
eval_input_reader: {
  tf_record_input_reader {
    input_path: "data/sim_data.record"
  }
  label_map_path: "data/label_map.pbtxt"
  shuffle: true
  num_readers: 1
}
```

`cd` to the base directory (/workspace). Copy the files `train.py` and `export_inference_graph.py` from the `tensorflow/projects/python/models/research/object_detection` to our current directory.

Before training take into account that the process takes well above 1 hour in the best case. **Depending on your GPU and the specific model to train, it can take something between 1-5 hours**.
Execute `python train.py --logtostderr --train_dir=./models/<model_folder>/train/ --pipeline_config_path=./models/<model_folder>/pipeline.config`. Training should start and you'll be able to see the progress.

### Freeze the graph

Open the `export_inference_graph.py` and comment lines 96-98, they should look like this after commenting:
```
#tf.app.flags.mark_flag_as_required('pipeline_config_path')
#tf.app.flags.mark_flag_as_required('trained_checkpoint_prefix')
#tf.app.flags.mark_flag_as_required('output_directory')
```

This is due to the flags attribute not existing in tf 1.3 (they were introduced in 1.4), but don't worry they don't break anything.
Now we can finally run `python export_inference_graph.py --input_type image_tensor --pipeline_config_path ./models/<model_folder>/train/pipeline.config --trained_checkpoint_prefix ./models/<model_folder>/train/model.ckpt-10000 --output_directory ./frozen_models/<model_name>`.
